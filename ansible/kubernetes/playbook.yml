---
# Kubernetes Installation Playbook
# Based on StackBill k8-common-installation.sh and k8-init.sh scripts
# Supports both master and worker node installation

- name: Install Kubernetes prerequisites on all nodes
  hosts: kubernetes
  become: true
  gather_facts: true
  vars:
    k8s_version: "{{ kubernetes_version | default('1.30') }}"
    load_balancer_ip: "{{ lb_ip | default(hostvars[groups['master'][0]]['ansible_host']) }}"

  pre_tasks:
    - name: Set custom hostname if provided
      hostname:
        name: "{{ custom_hostname }}"
      when: custom_hostname is defined and custom_hostname | length > 0

    - name: Update /etc/hosts with hostname
      lineinfile:
        path: /etc/hosts
        regexp: '^127\.0\.1\.1'
        line: "127.0.1.1 {{ custom_hostname }}"
        state: present
      when: custom_hostname is defined and custom_hostname | length > 0

  tasks:
    - name: Wait for apt locks to be released
      ansible.builtin.shell: |
        while fuser /var/lib/dpkg/lock >/dev/null 2>&1 || \
              fuser /var/lib/dpkg/lock-frontend >/dev/null 2>&1 || \
              fuser /var/lib/apt/lists/lock >/dev/null 2>&1; do
          echo "Waiting for apt locks (unattended-upgrades may be running)..."
          sleep 5
        done
      changed_when: false
      register: apt_lock_wait
      async: 300
      poll: 10

    - name: Verify Ubuntu version
      ansible.builtin.assert:
        that:
          - ansible_distribution == "Ubuntu"
          - ansible_distribution_version is version('22.04', '>=')
        fail_msg: "This playbook requires Ubuntu 22.04 or later"
        success_msg: "OS verification passed: {{ ansible_distribution }} {{ ansible_distribution_version }}"

    - name: Update apt cache
      ansible.builtin.apt:
        update_cache: yes
        cache_valid_time: 3600

    - name: Upgrade all packages
      ansible.builtin.apt:
        upgrade: dist
      register: upgrade_result

    - name: Install required packages
      ansible.builtin.apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gnupg
          - lsb-release
          - software-properties-common
          - nfs-common
        state: present

    - name: Display NFS client installation status
      ansible.builtin.debug:
        msg: "NFS client (nfs-common) installed for StackBill persistent volume access"

    - name: Disable swap
      ansible.builtin.command: swapoff -a
      changed_when: false

    - name: Remove swap from fstab
      ansible.builtin.lineinfile:
        path: /etc/fstab
        regexp: '^.*swap.*$'
        state: absent

    - name: Load required kernel modules
      ansible.builtin.modprobe:
        name: "{{ item }}"
        state: present
      loop:
        - overlay
        - br_netfilter

    - name: Ensure kernel modules load on boot
      ansible.builtin.copy:
        dest: /etc/modules-load.d/k8s.conf
        content: |
          overlay
          br_netfilter
        mode: '0644'

    - name: Configure sysctl for Kubernetes
      ansible.builtin.copy:
        dest: /etc/sysctl.d/k8s.conf
        content: |
          net.bridge.bridge-nf-call-iptables  = 1
          net.bridge.bridge-nf-call-ip6tables = 1
          net.ipv4.ip_forward                 = 1
        mode: '0644'

    - name: Apply sysctl settings
      ansible.builtin.command: sysctl --system
      changed_when: false

    - name: Add Docker GPG key
      ansible.builtin.apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present

    - name: Add Docker repository
      ansible.builtin.apt_repository:
        repo: "deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"
        state: present

    - name: Install containerd
      ansible.builtin.apt:
        name: containerd.io
        state: present
        update_cache: yes

    - name: Create containerd config directory
      ansible.builtin.file:
        path: /etc/containerd
        state: directory
        mode: '0755'

    - name: Configure containerd
      ansible.builtin.shell: containerd config default > /etc/containerd/config.toml
      args:
        creates: /etc/containerd/config.toml

    - name: Enable SystemdCgroup in containerd
      ansible.builtin.lineinfile:
        path: /etc/containerd/config.toml
        regexp: 'SystemdCgroup = false'
        line: '            SystemdCgroup = true'

    - name: Restart containerd
      ansible.builtin.service:
        name: containerd
        state: restarted
        enabled: yes

    - name: Add Kubernetes GPG key
      ansible.builtin.apt_key:
        url: https://pkgs.k8s.io/core:/stable:/v{{ k8s_version }}/deb/Release.key
        state: present

    - name: Add Kubernetes repository
      ansible.builtin.apt_repository:
        repo: "deb https://pkgs.k8s.io/core:/stable:/v{{ k8s_version }}/deb/ /"
        state: present
        filename: kubernetes

    - name: Install Kubernetes components
      ansible.builtin.apt:
        name:
          - kubelet
          - kubeadm
          - kubectl
        state: present
        update_cache: yes

    - name: Hold Kubernetes packages
      ansible.builtin.dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - kubelet
        - kubeadm
        - kubectl

    - name: Enable kubelet service
      ansible.builtin.service:
        name: kubelet
        enabled: yes

    - name: Display Kubernetes version
      ansible.builtin.command: kubeadm version -o short
      register: kubeadm_version
      changed_when: false

    - name: Show installed version
      ansible.builtin.debug:
        msg: "Kubernetes {{ kubeadm_version.stdout }} installed on {{ inventory_hostname }}"

# ==================== FIRST MASTER NODE INITIALIZATION ====================
- name: Initialize first Kubernetes master node
  hosts: master[0]
  become: true
  gather_facts: true
  vars:
    k8s_version: "{{ kubernetes_version | default('1.30') }}"
    pod_network_cidr: "10.244.0.0/16"
    # Use private IP for control-plane-endpoint, or lb_ip if provided
    node_ip: "{{ ansible_default_ipv4.address }}"
    load_balancer_ip: "{{ lb_ip | default(ansible_default_ipv4.address) }}"

  tasks:
    - name: Display node IP configuration
      ansible.builtin.debug:
        msg: "Node IP: {{ node_ip }}, Control Plane Endpoint: {{ load_balancer_ip }}"

    - name: Check if cluster is already initialized
      ansible.builtin.stat:
        path: /etc/kubernetes/admin.conf
      register: kubeadm_init_check

    - name: Initialize Kubernetes cluster (first master)
      ansible.builtin.command: >
        kubeadm init
        --pod-network-cidr={{ pod_network_cidr }}
        --apiserver-advertise-address={{ node_ip }}
        --control-plane-endpoint={{ load_balancer_ip }}:6443
        --upload-certs
      register: kubeadm_init
      when: not kubeadm_init_check.stat.exists

    - name: Extract certificate key from init output
      ansible.builtin.set_fact:
        certificate_key: "{{ kubeadm_init.stdout | regex_search('--certificate-key\\s+([a-f0-9]+)', '\\1') | first }}"
      when: kubeadm_init is changed and kubeadm_init.stdout is defined

    - name: Generate new certificate key if cluster already exists
      ansible.builtin.command: kubeadm init phase upload-certs --upload-certs
      register: upload_certs_output
      when: kubeadm_init_check.stat.exists
      changed_when: false

    - name: Extract certificate key from upload-certs output
      ansible.builtin.set_fact:
        certificate_key: "{{ upload_certs_output.stdout_lines | last }}"
      when: kubeadm_init_check.stat.exists and upload_certs_output.stdout is defined

    - name: Create .kube directory
      ansible.builtin.file:
        path: /root/.kube
        state: directory
        mode: '0700'

    - name: Copy admin.conf to .kube
      ansible.builtin.copy:
        src: /etc/kubernetes/admin.conf
        dest: /root/.kube/config
        remote_src: yes
        mode: '0600'

    - name: Install Flannel CNI
      ansible.builtin.command: kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
      register: flannel_install
      changed_when: "'created' in flannel_install.stdout or 'configured' in flannel_install.stdout"

    - name: Wait for first master to be ready
      ansible.builtin.command: kubectl wait --for=condition=Ready node/{{ inventory_hostname }} --timeout=300s
      register: master_ready
      retries: 5
      delay: 30
      until: master_ready.rc == 0
      changed_when: false

    - name: Generate join command for workers
      ansible.builtin.command: kubeadm token create --print-join-command
      register: join_command
      changed_when: false

    - name: Store join command and certificate key
      ansible.builtin.set_fact:
        kubernetes_join_command: "{{ join_command.stdout }}"
        kubernetes_certificate_key: "{{ certificate_key | default('') }}"

    - name: Display cluster initialization info
      ansible.builtin.debug:
        msg:
          - "Kubernetes First Master initialized successfully!"
          - "Additional masters will join as control-plane nodes"
          - "Workers will join as worker nodes"

    - name: Get cluster info
      ansible.builtin.command: kubectl cluster-info
      register: cluster_info
      changed_when: false

    - name: Display cluster info
      ansible.builtin.debug:
        msg: "{{ cluster_info.stdout_lines }}"

# ==================== ADDITIONAL MASTER NODES JOIN ====================
- name: Join additional master nodes to cluster
  hosts: master[1:]
  become: true
  gather_facts: true
  serial: 1
  vars:
    first_master: "{{ groups['master'][0] }}"
    node_ip: "{{ ansible_default_ipv4.address }}"

  tasks:
    - name: Display node IP for this master
      ansible.builtin.debug:
        msg: "Joining as control-plane with IP: {{ node_ip }}"

    - name: Check if node is already joined
      ansible.builtin.stat:
        path: /etc/kubernetes/admin.conf
      register: admin_conf_check

    - name: Get join command from first master
      ansible.builtin.set_fact:
        kubernetes_join_command: "{{ hostvars[first_master]['kubernetes_join_command'] }}"
        kubernetes_certificate_key: "{{ hostvars[first_master]['kubernetes_certificate_key'] }}"
      when: not admin_conf_check.stat.exists

    - name: Join as control-plane node
      ansible.builtin.command: >
        {{ kubernetes_join_command }}
        --control-plane
        --certificate-key {{ kubernetes_certificate_key }}
        --apiserver-advertise-address={{ node_ip }}
      register: control_plane_join
      when:
        - not admin_conf_check.stat.exists
        - kubernetes_join_command is defined
        - kubernetes_certificate_key is defined
        - kubernetes_certificate_key | length > 0

    - name: Create .kube directory
      ansible.builtin.file:
        path: /root/.kube
        state: directory
        mode: '0700'

    - name: Copy admin.conf to .kube
      ansible.builtin.copy:
        src: /etc/kubernetes/admin.conf
        dest: /root/.kube/config
        remote_src: yes
        mode: '0600'
      when: admin_conf_check.stat.exists or control_plane_join is changed

    - name: Wait for this master to be ready
      ansible.builtin.command: kubectl wait --for=condition=Ready node/{{ inventory_hostname }} --timeout=300s
      register: node_ready
      retries: 5
      delay: 30
      until: node_ready.rc == 0
      changed_when: false
      when: control_plane_join is changed

    - name: Display join result
      ansible.builtin.debug:
        msg: "{{ 'Control-plane node joined cluster successfully' if control_plane_join is changed else 'Node already in cluster as control-plane' }}"

# ==================== WORKER NODE JOIN ====================
- name: Join worker nodes to cluster
  hosts: worker
  become: true
  gather_facts: true
  vars:
    master_host: "{{ groups['master'][0] }}"

  tasks:
    - name: Check if node is already joined
      ansible.builtin.stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubelet_conf

    - name: Get join command from master
      ansible.builtin.set_fact:
        kubernetes_join_command: "{{ hostvars[master_host]['kubernetes_join_command'] }}"
      when: not kubelet_conf.stat.exists

    - name: Join worker to cluster
      ansible.builtin.command: "{{ kubernetes_join_command }}"
      register: join_result
      when:
        - not kubelet_conf.stat.exists
        - kubernetes_join_command is defined

    - name: Display join result
      ansible.builtin.debug:
        msg: "{{ 'Node joined cluster successfully' if join_result is changed else 'Node already in cluster' }}"

# ==================== FINAL VERIFICATION ====================
- name: Verify cluster status
  hosts: master[0]
  become: true
  gather_facts: false

  tasks:
    - name: Wait for all nodes to be ready
      ansible.builtin.command: kubectl wait --for=condition=Ready nodes --all --timeout=300s
      register: all_nodes_ready
      retries: 5
      delay: 30
      until: all_nodes_ready.rc == 0
      changed_when: false

    - name: Get all nodes
      ansible.builtin.command: kubectl get nodes -o wide
      register: nodes_list
      changed_when: false

    - name: Display all nodes
      ansible.builtin.debug:
        msg: "{{ nodes_list.stdout_lines }}"

    - name: Kubernetes Installation Summary
      ansible.builtin.debug:
        msg:
          - "======================================"
          - "KUBERNETES HA CLUSTER READY"
          - "======================================"
          - "Control Plane Nodes: {{ groups['master'] | length }}"
          - "Worker Nodes: {{ groups['worker'] | default([]) | length }}"
          - "API Server: https://{{ hostvars[groups['master'][0]]['ansible_host'] }}:6443"
          - ""
          - "Next Steps:"
          - "1. Copy kubeconfig to management node"
          - "2. Install kubectl and istio on management node"
          - "3. Deploy StackBill application"
          - "======================================"
