---
# Kubernetes Installation Playbook
# Based on StackBill k8-common-installation.sh and k8-init.sh scripts
# Supports both master and worker node installation

- name: Install Kubernetes prerequisites on all nodes
  hosts: kubernetes
  become: true
  gather_facts: true
  vars:
    k8s_version: "{{ kubernetes_version | default('1.30') }}"
    load_balancer_ip: "{{ lb_ip | default(hostvars[groups['master'][0]]['ansible_host']) }}"

  pre_tasks:
    - name: Set custom hostname if provided
      hostname:
        name: "{{ custom_hostname }}"
      when: custom_hostname is defined and custom_hostname | length > 0

    - name: Update /etc/hosts with hostname
      lineinfile:
        path: /etc/hosts
        regexp: '^127\.0\.1\.1'
        line: "127.0.1.1 {{ custom_hostname }}"
        state: present
      when: custom_hostname is defined and custom_hostname | length > 0

  tasks:
    - name: Verify Ubuntu version
      ansible.builtin.assert:
        that:
          - ansible_distribution == "Ubuntu"
          - ansible_distribution_version is version('22.04', '>=')
        fail_msg: "This playbook requires Ubuntu 22.04 or later"
        success_msg: "OS verification passed: {{ ansible_distribution }} {{ ansible_distribution_version }}"

    - name: Update apt cache
      ansible.builtin.apt:
        update_cache: yes
        cache_valid_time: 3600

    - name: Upgrade all packages
      ansible.builtin.apt:
        upgrade: dist
      register: upgrade_result

    - name: Install required packages
      ansible.builtin.apt:
        name:
          - apt-transport-https
          - ca-certificates
          - curl
          - gnupg
          - lsb-release
          - software-properties-common
          - nfs-common
        state: present

    - name: Display NFS client installation status
      ansible.builtin.debug:
        msg: "NFS client (nfs-common) installed for StackBill persistent volume access"

    - name: Disable swap
      ansible.builtin.command: swapoff -a
      changed_when: false

    - name: Remove swap from fstab
      ansible.builtin.lineinfile:
        path: /etc/fstab
        regexp: '^.*swap.*$'
        state: absent

    - name: Load required kernel modules
      ansible.builtin.modprobe:
        name: "{{ item }}"
        state: present
      loop:
        - overlay
        - br_netfilter

    - name: Ensure kernel modules load on boot
      ansible.builtin.copy:
        dest: /etc/modules-load.d/k8s.conf
        content: |
          overlay
          br_netfilter
        mode: '0644'

    - name: Configure sysctl for Kubernetes
      ansible.builtin.copy:
        dest: /etc/sysctl.d/k8s.conf
        content: |
          net.bridge.bridge-nf-call-iptables  = 1
          net.bridge.bridge-nf-call-ip6tables = 1
          net.ipv4.ip_forward                 = 1
        mode: '0644'

    - name: Apply sysctl settings
      ansible.builtin.command: sysctl --system
      changed_when: false

    - name: Add Docker GPG key
      ansible.builtin.apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present

    - name: Add Docker repository
      ansible.builtin.apt_repository:
        repo: "deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"
        state: present

    - name: Install containerd
      ansible.builtin.apt:
        name: containerd.io
        state: present
        update_cache: yes

    - name: Create containerd config directory
      ansible.builtin.file:
        path: /etc/containerd
        state: directory
        mode: '0755'

    - name: Configure containerd
      ansible.builtin.shell: containerd config default > /etc/containerd/config.toml
      args:
        creates: /etc/containerd/config.toml

    - name: Enable SystemdCgroup in containerd
      ansible.builtin.lineinfile:
        path: /etc/containerd/config.toml
        regexp: 'SystemdCgroup = false'
        line: '            SystemdCgroup = true'

    - name: Restart containerd
      ansible.builtin.service:
        name: containerd
        state: restarted
        enabled: yes

    - name: Add Kubernetes GPG key
      ansible.builtin.apt_key:
        url: https://pkgs.k8s.io/core:/stable:/v{{ k8s_version }}/deb/Release.key
        state: present

    - name: Add Kubernetes repository
      ansible.builtin.apt_repository:
        repo: "deb https://pkgs.k8s.io/core:/stable:/v{{ k8s_version }}/deb/ /"
        state: present
        filename: kubernetes

    - name: Install Kubernetes components
      ansible.builtin.apt:
        name:
          - kubelet
          - kubeadm
          - kubectl
        state: present
        update_cache: yes

    - name: Hold Kubernetes packages
      ansible.builtin.dpkg_selections:
        name: "{{ item }}"
        selection: hold
      loop:
        - kubelet
        - kubeadm
        - kubectl

    - name: Enable kubelet service
      ansible.builtin.service:
        name: kubelet
        enabled: yes

    - name: Display Kubernetes version
      ansible.builtin.command: kubeadm version -o short
      register: kubeadm_version
      changed_when: false

    - name: Show installed version
      ansible.builtin.debug:
        msg: "Kubernetes {{ kubeadm_version.stdout }} installed on {{ inventory_hostname }}"

# ==================== MASTER NODE INITIALIZATION ====================
- name: Initialize Kubernetes master node
  hosts: master
  become: true
  gather_facts: true
  vars:
    k8s_version: "{{ kubernetes_version | default('1.30') }}"
    pod_network_cidr: "10.244.0.0/16"
    load_balancer_ip: "{{ lb_ip | default(ansible_host) }}"

  tasks:
    - name: Check if cluster is already initialized
      ansible.builtin.stat:
        path: /etc/kubernetes/admin.conf
      register: kubeadm_init_check

    - name: Initialize Kubernetes cluster
      ansible.builtin.command: >
        kubeadm init
        --pod-network-cidr={{ pod_network_cidr }}
        --apiserver-advertise-address={{ ansible_host }}
        --control-plane-endpoint={{ load_balancer_ip }}:6443
      register: kubeadm_init
      when: not kubeadm_init_check.stat.exists

    - name: Create .kube directory
      ansible.builtin.file:
        path: /root/.kube
        state: directory
        mode: '0700'

    - name: Copy admin.conf to .kube
      ansible.builtin.copy:
        src: /etc/kubernetes/admin.conf
        dest: /root/.kube/config
        remote_src: yes
        mode: '0600'

    - name: Install Flannel CNI
      ansible.builtin.command: kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
      register: flannel_install
      changed_when: "'created' in flannel_install.stdout or 'configured' in flannel_install.stdout"

    - name: Wait for control plane to be ready
      ansible.builtin.command: kubectl wait --for=condition=Ready nodes --all --timeout=300s
      register: nodes_ready
      retries: 5
      delay: 30
      until: nodes_ready.rc == 0
      changed_when: false

    - name: Generate join command for workers
      ansible.builtin.command: kubeadm token create --print-join-command
      register: join_command
      changed_when: false

    - name: Store join command
      ansible.builtin.set_fact:
        kubernetes_join_command: "{{ join_command.stdout }}"

    - name: Display join command
      ansible.builtin.debug:
        msg:
          - "Kubernetes Master initialized successfully!"
          - "Join command for workers:"
          - "{{ kubernetes_join_command }}"

    - name: Get cluster info
      ansible.builtin.command: kubectl cluster-info
      register: cluster_info
      changed_when: false

    - name: Display cluster info
      ansible.builtin.debug:
        msg: "{{ cluster_info.stdout_lines }}"

# ==================== WORKER NODE JOIN ====================
- name: Join worker nodes to cluster
  hosts: worker
  become: true
  gather_facts: true
  vars:
    master_host: "{{ groups['master'][0] }}"

  tasks:
    - name: Check if node is already joined
      ansible.builtin.stat:
        path: /etc/kubernetes/kubelet.conf
      register: kubelet_conf

    - name: Get join command from master
      ansible.builtin.set_fact:
        kubernetes_join_command: "{{ hostvars[master_host]['kubernetes_join_command'] }}"
      when: not kubelet_conf.stat.exists

    - name: Join worker to cluster
      ansible.builtin.command: "{{ kubernetes_join_command }}"
      register: join_result
      when:
        - not kubelet_conf.stat.exists
        - kubernetes_join_command is defined

    - name: Display join result
      ansible.builtin.debug:
        msg: "{{ 'Node joined cluster successfully' if join_result is changed else 'Node already in cluster' }}"

# ==================== FINAL VERIFICATION ====================
- name: Verify cluster status
  hosts: master
  become: true
  gather_facts: false

  tasks:
    - name: Wait for all nodes to be ready
      ansible.builtin.command: kubectl wait --for=condition=Ready nodes --all --timeout=300s
      register: all_nodes_ready
      retries: 3
      delay: 30
      until: all_nodes_ready.rc == 0
      changed_when: false

    - name: Get all nodes
      ansible.builtin.command: kubectl get nodes -o wide
      register: nodes_list
      changed_when: false

    - name: Display all nodes
      ansible.builtin.debug:
        msg: "{{ nodes_list.stdout_lines }}"

    - name: Kubernetes Installation Summary
      ansible.builtin.debug:
        msg:
          - "======================================"
          - "KUBERNETES CLUSTER READY"
          - "======================================"
          - "Master: {{ ansible_host }}"
          - "Workers: {{ groups['worker'] | default([]) | length }}"
          - "API Server: https://{{ ansible_host }}:6443"
          - ""
          - "Next Steps:"
          - "1. Copy kubeconfig to management node"
          - "2. Install kubectl and istio on management node"
          - "3. Deploy StackBill application"
          - "======================================"
